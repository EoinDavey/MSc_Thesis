\chapter{SDP Verification}
\label{app:sdp_verification}

When we apply an SDP solver to our problems as in appendix \ref{app:flag_software}
we have claimed that the SDP solver will give us a matrix which proves the claimed bound.
However, these SDP solvers are numerical algorithms meaning they can only give us a very
close approximation of what they claim. This is in particular due to the mechanics of
floating point arithmetic. To be rigorous we need to take these \textit{approximate}
solutions and find a true solution which achieves the same results.
For some results we have a very tight bound (e.g. lemma \ref{lemma:pentagon_1_4_bound}
is best possible by lemma \ref{lemma:pentagon_1_8_tight}). In these cases we cannot afford
to introduce any error when finding a true solution close to the approximate one. In
other cases there is some room for "rounding" of the approximate solution.

In section \ref{sec:pentagon_proof_validation} we showed the results of converting an
SDP solution back into a standalone proof. This was done for elucidatory purposes,
confirming that the SDP solutions do indeed correspond to a convex combination of elements
of the semantic cone. In this first section we will discuss how this was done.
However, this full conversion to a standalone proof is not necessary: In the second
section we will discuss how you might verify that SDP solution is sound without as much
manual effort.

The certificate files generated by the search programs can be found in the
\verb|certificates/| directory of the \url{https://github.com/EoinDavey/local-flags}
repository.

\section*{Conversion to Standalone Proof}

The SDP software outlined in appendix \ref{app:flag_software} contains some
functionality to find a minimised set of constraints. It does this by
running the search with all constraints, then removing them one at a time so long as
the optimum solution is maintained. The function which does this is
\verb|FlagSolver::minimize|. There are several such methods implemented but I
only verified the correctness of \verb|minimize| as implemented in the
\url{github.com/EoinDavey/rust-flag-algebra} fork of the \verb|rust-flag-algebra|
library.

\begin{note*}
    CSDP will fail to run if there are any variables which have no associated constraints.
    For that reason I recommend using the \verb|.protect| method to prevent the minimising
    process from removing the $F \geq 0\ \forall F$ inequalities.
\end{note*}

This minimisation process reduces the size of the dual matrices that we need to deal with.
However, if the search process itself is slow, then this process will be extremely slow.
Hence it has limited applications for larger problems.

Given then a dual certificate (minimised or not) from our SDP program it will be in
SDPA-Sparse format. This is a sparse block-diagonal format of describing a matrix.
These blocks then correspond to the coefficients associated with our inequalities. i.e.
they are blocks of size 1 for linear inequalities or PSD matrices for the Cauchy-Schwarz
$\llbracket f^2 \rrbracket \geq 0$ inequalities. In the
\url{github.com/EoinDavey/rust-flag-algebra} repository you will find a
Python\footnote{\url{https://python.org/}} script \verb|sdpa_parse.py| which can
interpret the SDPA problem input file and certificate file.

At this point the main goal is to remove floating point inaccuracy. In practice you
will find that most coefficients are clearly floating point approximations of identifiable
rationals, $1/4$, $7/5$ etc. To do this process of replacing floating point approximations with
their associated rational I copied the \verb|sdpa_parse.py| file and modified it to
overwrite the associated coefficients, while asserting that we still get an
objective function bound close to what we expected.
This was a tedious manual process but after some time I had converted the coefficients to
nice rationals.

Modifying the entries of PSD matrices may render them no longer PSD so
I needed to check that each such matrix was still PSD. After obtaining these rational
PSD matrices I wanted to extract the associated vectors $\nu_i$ which give us the
elements $\llbracket \nu_i^2 \rrbracket$ as described in section \ref{sec:sdp_duality}.
The most direct way to do this is to compute the spectral decomposition, I used
\url{https://wolframalpha.com/} to do this symbolically. However, one of the PSD matrices
gave me some "ugly" coefficients such as $\sqrt{11 + \sqrt{89}}$. For that matrix
I instead used the Z3 Solver\footnote{\url{https://www.microsoft.com/en-us/research/project/z3-3/}}
to find a nicer set of vectors $\nu_i$ such that $\sum_i \nu_i\nu_i^T$ gave the same
matrix. This was just an aesthetic choice.

\begin{note*}
    When researching this project I found the paper
    \textit{Exact Semidefinite Programming Bounds for Packing Problems} by
    Dostert, de Laat and Moustrou \cite{dostertExactSemidefiniteProgramming2021}
    which describes a more mathematical approach to making a floating point SDP solution
    exact. I didn't use this approach but I think it's valuable to mention it here.
\end{note*}

\section*{Verification Without Conversion}

Most of the results in this thesis are not "tight", in the sense that we are rounding
the SDP solutions up. e.g. In lemma \ref{lemma:sec_sdp_soln} we give the result that
$10.644\emptyset - O \in\SemCone^\emptyset$, but in fact the SDP solver claims a
better result of $10.643189$. Rounding up gives us some room to maneuver with respect
to the floating point, while still achieving the nice $1.73$ bound of theorem
\ref{thm:strong_edge_colouring_bound}.

For the results in this thesis (other than section \ref{sec:pentagon_proof_validation})
we did not go through a full verification as we felt it
fell outside the scope of this research project, being more a manual process required for
full publication of the results. However, I will briefly describe here how this process
would work.

First, we should ensure that the SDP problems our programs generate are full precision.
In practice we do this by expressing every problem in terms of rationals and then scaling
expressions by common denominators to get SPD problems expressed entirely as integers.
Then, the SDP solver will give us a solution as a matrix of floating point numbers. We
can interpret this matrix as a list of coefficients $c_i > 0$ and PSD matrices $P_k$
(section \ref{sec:sdp_duality}) as implemented in \verb|sdpa_parse.py|. Each of the 
coefficients can be interpreted from its floating point representation to some
rational $\overline{c_i} > 0$. We could try to cast the entries of the matrices $P_k$
in the same fashion but we need the resulting $\overline{P_k}$ to definitely be PSD.
We know $P_k$ is PSD up to floating point precision so we apply a numerical algorithm
to compute it's spectral decomposition $P_k=\sum_j\nu_{k,j}\nu_{k,j}^T$. We then cast
each of these vectors $\nu_{j,k}$ as rationals $\overline{\nu_{j,k}}$ and compute
$\overline{P_k}=\sum_j\overline{\nu_{j,k}}\overline{\nu_{j,k}}^T$ which by construction
is definitely PSD.

Now we expect to get
\[
    \sum_i \overline{c_i} v_i + \sum_k \sum_j \llbracket \overline{\nu_{j,k}}^2 \rrbracket
    = \lambda\emptyset - O + \varepsilon
    \in \SemCone
\]
where $O$ is our objective vector and $v_i$ are the fixed elements of
$\SemCone^\emptyset$. We expect that $\lambda$ should be close enough to
the bound we want to prove and $\varepsilon$ is some small error vector which is
left over. This proves that $\phi(O) \leq \lambda - \phi(\varepsilon)$ for all
$\phi\in\Phi^\emptyset$. If we can bound the size of $\phi(\varepsilon)$ then we can
get a proper bound on $\phi(O)$.

An alternative strategy is to try and minimise the size of $\varepsilon$. To do this
we could take our list of known elements $v_1, \dots, v_k$ and the
vectors $\llbracket \overline{\nu_{j,k}}^2\rrbracket$ and treat this as
a linear programming problem. There exist exact LP solvers over there which
use rational arithmetic so don't suffer from floating point error.
eg. \url{https://www.math.uwaterloo.ca/~bico/qsopt/ex/}.
